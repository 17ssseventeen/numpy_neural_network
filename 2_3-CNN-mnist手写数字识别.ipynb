{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络\n",
    "\n",
    "\n",
    "    input(N,1,28,28)=>conv(32,3,3)=>conv(32,3,3)=>relu=>max_pooling(2,2)=>conv(64,3,3)=>conv(64,3,3)=>global_avg_pooling=>fc(10)=>softmax\n",
    "\n",
    "                    (N,32,26,26)  (N,32,24,24)           (N,32,12,12)      (N,64,10,10)   (N,64,8,8)      (N,64)       (N,10)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pooling_forward(z, pooling, strides=(2, 2), padding=(0, 0)):\n",
    "    \"\"\"\n",
    "    最大池化前向过程\n",
    "    :param z: 卷积层矩阵,形状(N,C,H,W)，N为batch_size，C为通道数\n",
    "    :param pooling: 池化大小(k1,k2)\n",
    "    :param strides: 步长\n",
    "    :param padding: 0填充\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    N, C, H, W = z.shape\n",
    "    # 零填充\n",
    "    padding_z = np.lib.pad(z, ((0, 0), (0, 0), (padding[0], padding[0]), (padding[1], padding[1])), 'constant', constant_values=0)\n",
    "\n",
    "    # 输出的高度和宽度\n",
    "    out_h = (H + 2 * padding[0] - pooling[0]) // strides[0] + 1\n",
    "    out_w = (W + 2 * padding[1] - pooling[1]) // strides[1] + 1\n",
    "\n",
    "    pool_z = np.zeros((N, C, out_h, out_w))\n",
    "    for n in np.arange(N):\n",
    "        for c in np.arange(C):\n",
    "            for i in np.arange(out_h):\n",
    "                for j in np.arange(out_w):\n",
    "\n",
    "                    pool_z[n, c, i, j] = np.max(padding_z[n, c,\n",
    "                                                          strides[0] * i:strides[0] * i + pooling[0],\n",
    "                                                          strides[1] * j:strides[1] * j + pooling[1]])\n",
    "    return pool_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 定义权重、神经元、梯度\n",
    "weights={}\n",
    "weights_scale=1e-3\n",
    "weights[\"K1\"]=weights_scale*np.random.randn(1,32,3,3)\n",
    "weights[\"b1\"]=np.zeros(32)\n",
    "weights[\"K2\"]=weights_scale*np.random.randn(32,32,3,3)\n",
    "weights[\"b2\"]=np.zeros(32)\n",
    "weights[\"K3\"]=weights_scale*np.random.randn(32,64,3,3)\n",
    "weights[\"b3\"]=np.zeros(64)\n",
    "weights[\"K4\"]=weights_scale*np.random.randn(64,64,3,3)\n",
    "weights[\"b4\"]=np.zeros(64)\n",
    "weights[\"W5\"]=weights_scale*np.random.randn(64,10)\n",
    "weights[\"b5\"]=np.zeros(10)\n",
    "\n",
    "nuerons={}\n",
    "gradients={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nn.layers import conv_forward,conv_backward,fc_forward,fc_backward\n",
    "from nn.layers import max_pooling_backward,global_avg_pooling_forward,global_avg_pooling_backward #,max_pooling_forward\n",
    "from nn.activations import relu_forward,relu_backward\n",
    "from nn.losses import cross_entropy_loss\n",
    "# 定义前向传播\n",
    "def forward(X):\n",
    "    nuerons[\"conv1\"]=conv_forward(X,weights[\"K1\"],weights[\"b1\"])\n",
    "    nuerons[\"conv2\"]=conv_forward(nuerons[\"conv1\"],weights[\"K2\"],weights[\"b2\"])\n",
    "    nuerons[\"conv2_relu\"]=relu_forward(nuerons[\"conv2\"])\n",
    "    nuerons[\"maxp\"]=max_pooling_forward(nuerons[\"conv2_relu\"],pooling=(2,2))\n",
    "    nuerons[\"conv3\"]=conv_forward(nuerons[\"maxp\"],weights[\"K3\"],weights[\"b3\"])\n",
    "    nuerons[\"conv4\"]=conv_forward(nuerons[\"conv3\"],weights[\"K4\"],weights[\"b4\"])\n",
    "    nuerons[\"gavgp\"]=global_avg_pooling_forward(nuerons[\"conv4\"])\n",
    "    nuerons[\"y\"]=fc_forward(nuerons[\"gavgp\"],weights[\"W5\"],weights[\"b5\"])\n",
    "    print(\"conv4.shape:{}\".format(nuerons[\"conv4\"].shape))\n",
    "    return nuerons[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义反向传播\n",
    "def backward(X,y_true):\n",
    "    loss,dy=cross_entropy_loss(nuerons[\"y\"],y_true)\n",
    "    print(\"dy:{}\".format(dy.shape))\n",
    "    gradients[\"W5\"],gradients[\"b5\"],gradients[\"gavgp\"]=fc_backward(dy,weights[\"W5\"],nuerons[\"gavgp\"])\n",
    "    print(\"gavgp:{}\".format(gradients[\"gavgp\"].shape))\n",
    "    gradients[\"conv4\"]=global_avg_pooling_backward(gradients[\"gavgp\"],nuerons[\"conv4\"])\n",
    "    print(\"conv4:{}\".format(gradients[\"conv4\"].shape))\n",
    "    gradients[\"K4\"],gradients[\"b4\"],gradients[\"conv3\"]=conv_backward(gradients[\"conv4\"],weights[\"K4\"],nuerons[\"conv3\"])\n",
    "    print(\"conv3:{}\".format(gradients[\"conv3\"].shape))\n",
    "    gradients[\"K3\"],gradients[\"b3\"],gradients[\"maxp\"]=conv_backward(gradients[\"conv3\"],weights[\"K3\"],nuerons[\"maxp\"])\n",
    "    print(\"maxp:{}\".format(gradients[\"maxp\"].shape))\n",
    "    gradients[\"conv2_relu\"]=max_pooling_backward(gradients[\"maxp\"],nuerons[\"conv2_relu\"],pooling=(2,2))\n",
    "    print(\"conv2_relu:{}\".format(gradients[\"conv2_relu\"].shape))\n",
    "    gradients[\"conv2\"]=relu_backward(gradients[\"conv2_relu\"],nuerons[\"conv2\"])\n",
    "    print(\"conv2:{}\".format(gradients[\"conv2\"].shape))\n",
    "    gradients[\"K2\"],gradients[\"b2\"],gradients[\"conv1\"]=conv_backward(gradients[\"conv2\"],weights[\"K2\"],nuerons[\"conv1\"])\n",
    "    print(\"conv1:{}\".format(gradients[\"conv1\"].shape))\n",
    "    gradients[\"K1\"],gradients[\"b1\"],_=conv_backward(gradients[\"conv1\"],weights[\"K1\"],X)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取精度\n",
    "def get_accuracy(X,y_true):\n",
    "    y_predict=forward(X)\n",
    "    return np.mean(np.equal(np.argmax(y_predict,axis=-1),\n",
    "                            np.argmax(y_true,axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nn.load_mnist import load_mnist_datasets\n",
    "from nn.utils import to_categorical\n",
    "train_set, val_set, test_set = load_mnist_datasets('mnist.pkl.gz')\n",
    "train_x,val_x,test_x=np.reshape(train_set[0],(-1,1,28,28)),np.reshape(val_set[0],(-1,1,28,28)),np.reshape(test_set[0],(-1,1,28,28))\n",
    "\n",
    "train_y,val_y,test_y=to_categorical(train_set[1]),to_categorical(val_set[1]),to_categorical(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:(16, 1, 28, 28),y.shape:(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# 随机选择训练样本\n",
    "train_num = train_set[0].shape[0]\n",
    "def next_batch(batch_size):\n",
    "    idx=np.random.choice(train_num,batch_size)\n",
    "    return train_x[idx],train_y[idx]\n",
    "\n",
    "x,y= next_batch(16)\n",
    "print(\"x.shape:{},y.shape:{}\".format(x.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4.shape:(2, 64, 8, 8)\n",
      "dy:(2, 10)\n",
      "gavgp:(2, 64)\n",
      "conv4:(2, 64, 8, 8)\n",
      "conv3:(2, 64, 10, 10)\n",
      "maxp:(2, 32, 12, 12)\n",
      "conv2_relu:(2, 32, 24, 24)\n",
      "conv2:(2, 32, 24, 24)\n",
      "conv1:(2, 32, 26, 26)\n",
      "\n",
      " epoch:0 step:0 ; loss:2.3025850930358502\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-00f7d49680aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n epoch:{} step:{} ; loss:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" train_acc:{};  val_acc:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "from nn.optimizers import SGD\n",
    "# 初始化变量\n",
    "batch_size=2\n",
    "epoch = 3\n",
    "steps = train_num // batch_size\n",
    "lr = 0.1\n",
    "\n",
    "for e in range(epoch):\n",
    "    for s in range(steps):\n",
    "        X,y=next_batch(batch_size)\n",
    "        \n",
    "        # 前向过程\n",
    "        forward(X)\n",
    "        loss=backward(X,y)\n",
    "        \n",
    "        # 更新梯度\n",
    "        for k in weights.keys():\n",
    "            weights[k]-=lr*gradients[k]\n",
    "        \n",
    "        if s % 10 ==0:\n",
    "            print(\"\\n epoch:{} step:{} ; loss:{}\".format(e,s,loss))\n",
    "            print(\" train_acc:{};  val_acc:{}\".format(get_accuracy(X,y),get_accuracy(val_x,val_y)))\n",
    "\n",
    "            \n",
    "print(\"\\n final result test_acc:{};  val_acc:{}\".\n",
    "      format(get_accuracy(test_x,test_y),get_accuracy(val_x,val_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
