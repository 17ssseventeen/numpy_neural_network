# numpy_neuron_network
仅使用numpy从头构建神经网络, 包括如下内容(更新中....)

0. 网络中梯度反向传播公式推导


1. 层：FC层,卷积层,池化层,Flatten
2. 激活函数: relu
3. 损失函数：均方差、交叉熵
4. 模型的保存、部署
5. 案例学习：线性回归、图像分类
6. 迁移学习、模型精调

[TOC]

## 基础知识

[0_1-全连接层、损失函数的反向传播](0_1-全连接层、损失函数的反向传播.md)

[0_2_1-卷积层的反向传播-单通道、无padding、步长1](0_2_1-卷积层的反向传播-单通道、无padding、步长1.md)

[0_2_2-卷积层的反向传播-多通道、无padding、步长1](0_2_2-卷积层的反向传播-多通道、无padding、步长1.md)

[0_2_3-卷积层的反向传播-多通道、无padding、步长不为1](0_2_3-卷积层的反向传播-多通道、无padding、步长不为1.md)

[0_3-激活函数的反向传播-ReLU、LeakyReLU、PReLU、ELU、SELU](0_3-激活函数的反向传播-ReLU、LeakyReLU、PReLU、ELU、SELU)



## DNN练习

[1_1_1-全连接神经网络做线性回归](1_1_1-全连接神经网络做线性回归.md)

[1_1_2-全连接神经网络做mnist手写数字识别](1_1_2-全连接神经网络做mnist手写数字识别.md)



## CNN练习

2_1-手写数字识别



## 模型的保存、部署



## 精调网络



